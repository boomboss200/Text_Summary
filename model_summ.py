# -*- coding: utf-8 -*-
"""Summarizer-Phase2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BRzUcv7HDnKFTleufPzF11VxQ0CiqezU
"""

import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation

text = "Your social networks and your location within them shape the kinds and amount of information that you have access to. Information is distinct from data, in that makes some kind of generalization about a person, thing, or population. Defensible generalizations about society can be either probabilities (i.e., statistics) or patterns (often from qualitative analysis). Such probabilities and patterns can be temporal, spatial, or simultaneous."

def summarizer(rawdocs):
  stopwords = list(STOP_WORDS)
  print(stopwords)

  nlp = spacy.load('en_core_web_sm')
  doc = nlp(rawdocs)

  print(doc)

  tokens = [token.text for token in doc]
  print(tokens)

  word_freq = {}
  for word in doc:
    if word.text.lower() not in stopwords and word.text.lower() not in punctuation:
      if word.text not in word_freq.keys():
        word_freq[word.text] = 1
      else:
        word_freq[word.text] += 1

  print(word_freq)

  max_freq = max(word_freq.values())
  print(max_freq)

  for word in word_freq.keys():
      word_freq[word] = word_freq[word]/max_freq

  print(word_freq)

  sent_tokens = [sent for sent in doc.sents]
  print(sent_tokens)

  sent_scores = {}
  for sent in sent_tokens:
    for word in sent:
      if word.text in word_freq.keys():
        if sent not in sent_scores.keys():
          sent_scores[sent] = word_freq[word.text]
        else:
          sent_scores[sent] += word_freq[word.text]


  print(sent_scores)

  select_len = int(len(sent_tokens) * 0.3)
  print(select_len)

  from heapq import nlargest

  summary = nlargest(select_len, sent_scores, key = sent_scores.get)
  print(summary)

  final_summary = [word.text for word in summary]
  summary = ' ' .join(final_summary)
  print(summary)

  # print(text)
  # print("Length of Original text: ", len(text.split(' ')))
  # print(summary)
  # print("Length of Original Summary: ", len(summary.split(' ')))
  return summary, doc, len(rawdocs.split(' ')), len(summary.split(' '))